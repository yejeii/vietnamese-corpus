{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 301 형식, 구어체로만 구성된 폴더 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import docx\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import re\n",
    "import win32com.client\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from pymysql import MySQLError\n",
    "\n",
    "def get_file_info(file_path):\n",
    "    file_size = os.path.getsize(file_path)                  # 파일 크기를 바이트 단위로 가져오기 \n",
    "    file_creation_time = os.path.getctime(file_path)        # 파일 생성일자를 가져오기\n",
    "    file_modification_time = os.path.getmtime(file_path)    # 파일 최종 수정일자를 가져오기\n",
    "    # file_name = os.path.basename(file_path)                 # 파일명 추출\n",
    "    file_name, file_extension = os.path.splitext(os.path.basename(file_path))                 # 확장명 뺀 파일명 추출\n",
    "    \n",
    "    return file_name, file_size, file_creation_time, file_modification_time\n",
    "\n",
    "def format_time(timestamp):\n",
    "    dt_object = datetime.fromtimestamp(timestamp)               # 에포크 시간을 datetime 객체로 변환\n",
    "    formatted_time = dt_object.strftime('%Y-%m-%d %H:%M:%S')    # 원하는 형식으로 시간을 포맷팅\n",
    "    \n",
    "    return formatted_time\n",
    "\n",
    "def count_words_docx(file_path):\n",
    "    total_words = 0\n",
    "    doc = docx.Document(file_path)\n",
    "\n",
    "    for paragraph in doc.paragraphs:\n",
    "        total_words += len(paragraph.text.split())   # 문서 내 단어 수 세기 \n",
    "\n",
    "    return total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 복제\n",
    "import shutil\n",
    "\n",
    "input_file = '2023-12-06 구어체'\n",
    "input_root = os.path.join('Z:/', input_file)\n",
    "\n",
    "# shutil.copytree('복사 대상 위치', '붙여넣기할 대상 위치')\n",
    "# 기본적으로 2번째 인자 폴더를 makedir하기 때문에 마지막 하위 폴더명이 존재하면 안됨.\n",
    "if __name__ == '__main__':\n",
    "    shutil.copytree(\n",
    "        # 'Z:/2023-11-15 구어체/',\n",
    "        input_root,\n",
    "        # 'Y:/구어체_모음' -- 이 폴더가 이미 존재하기 때문에 처리가 안됨.\n",
    "        os.path.join('Y:/구어체_모음', input_file)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL 연결 정보\n",
    "mysql_host = '172.30.1.36'\n",
    "mysql_port = 13333\n",
    "mysql_user = 'vnc'\n",
    "mysql_password = 'vnc'\n",
    "mysql_database = 'vnc'\n",
    "\n",
    "\n",
    "excel_tb = 'load_vnc_org_lst_sim_20231207_05'\n",
    "file_tb = 'load_vnc_file_list_sim_20231207_05'\n",
    "docx_tb = 'load_vnc_file_docx_sim_20231207_05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL database for create table.\n",
      "Create succeeded.\n",
      "DB is disconnected.\n"
     ]
    }
   ],
   "source": [
    "# 테이블 생성 쿼리\n",
    "\n",
    "# 테이블 생성하는 쿼리문 결과\n",
    "CREATE_TABLE = False  # 기본적으로 fALSE로 초기화\n",
    "\n",
    "try:    \n",
    "    db = pymysql.connect(host=mysql_host,port=mysql_port,user=mysql_user,passwd=mysql_password,db=mysql_database)\n",
    "    cursor = db.cursor(pymysql.cursors.DictCursor)\n",
    "    print(\"Connected to MySQL database for create table.\")\n",
    "    \n",
    "    create_query = f'CREATE TABLE {excel_tb} LIKE vnc.load_vnc_org_lst_sim;'\n",
    "    cursor.execute(create_query)    # 쿼리 실행\n",
    "\n",
    "    create_query = f'CREATE TABLE {file_tb} LIKE vnc.load_vnc_file_list_sim;'\n",
    "    cursor.execute(create_query)\n",
    "\n",
    "    create_query = f'CREATE TABLE {docx_tb} LIKE vnc.load_vnc_file_docx_sim;'\n",
    "    cursor.execute(create_query)\n",
    "   \n",
    "    db.commit() # 변경사항 DB에 반영\n",
    "    \n",
    "    create_idx_q = f'CREATE INDEX {docx_tb}_FILE_TXT_IDX USING BTREE ON {docx_tb} (FILE_TXT);'\n",
    "    cursor.execute(create_idx_q)    # 쿼리 실행\n",
    "    db.commit() # 변경사항 DB에 반영\n",
    "    \n",
    "    print(\"Create succeeded.\")\n",
    "    CREATE_TABLE = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"에러 발생: {e}\")\n",
    "    sql = ''\n",
    "    sql += f'DROP TABLE IF EXISTS {excel_tb};'\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    sql = 'DROP TABLE IF EXISTS {file_tb};'\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    sql = 'DROP TABLE IF EXISTS {docx_tb};'\n",
    "    cursor.execute(sql)\n",
    "\n",
    "finally:\n",
    "    db.close()\n",
    "    cursor.close()\n",
    "    print(f\"DB is disconnected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CW040\n",
      "CW044\n",
      "CW045\n",
      "CW046\n",
      "CW048\n",
      "CW049\n",
      "CW050\n",
      "CW051\n"
     ]
    }
   ],
   "source": [
    "root_path = 'Y:/구어체_모음/2023-11-27 구어체/'\n",
    "\n",
    "JOB_YMD = ''\n",
    "WORKER_ID = ''\n",
    "\n",
    "worker_folders = os.listdir(root_path)\n",
    "for worker in worker_folders:\n",
    "    WORKER_ID = worker\n",
    "    \n",
    "    if len(WORKER_ID) > 5 :\n",
    "        # 작업자 폴더 길이가 5를 초과하면 해당 파일 처리를 건너뜀.(자동화로 처리된 파일)\n",
    "        continue\n",
    "    \n",
    "    worker_path = os.path.join(root_path, worker)\n",
    "    \n",
    "    job_folder = os.listdir(worker_path)[0]  # 가장 첫번째 폴더 가져옴\n",
    "    job_folder_path = os.path.join(worker_path, job_folder)\n",
    "    \n",
    "    JOB_YMD = os.path.basename(job_folder_path) # 가장 마지막 경로명 추출\n",
    "    # WORKER_ID = os.path.dirname(job_folder_path)    # 가장 마지막 경로명의 상위 경로 추출 (Y:/구어체_모음/2023-11-15 구어체/CW040)\n",
    "    print(WORKER_ID)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업자 작업경로\n",
    "# root_path = 'Y:/구어체_모음/2023-11-10 구어체/CW040/20231110/'\n",
    "# root_path = 'Y:/구어체_모음/2023-11-10 구어체/CW044/20231110-1/'\n",
    "# root_path = 'Y:/구어체_모음/2023-11-10 구어체/CW046/20231110-1/'\n",
    "# root_path = 'Y:/구어체_모음/2023-11-10 구어체/CW047/20231110-1/'\n",
    "# root_path = 'Y:/구어체_모음/2023-11-10 구어체/CW048/20231110/'\n",
    "# root_path = 'Y:/구어체_모음/2023-11-10 구어체/CW049/20231110/'\n",
    "# root_path = 'Y:/구어체_모음/2023-11-10 구어체/CW050/20231110-1/'\n",
    "# root_path = 'Y:/구어체_모음/2023-11-10 구어체/CW051/20231110-1/'\n",
    "# root_path = 'Y:/구어체_모음/2023-11-10 구어체/CW044/20231110-2/'\n",
    "# root_path = 'Y:/구어체_모음/2023-11-10 구어체/CW046/20231110-2/'\n",
    "# root_path = 'Y:\\\\구어체_모음\\\\2023-11-10 구어체\\\\CW047\\\\20231110-2/'\n",
    "# root_path = 'Y:\\\\구어체_모음\\\\2023-11-10 구어체\\\\CW050\\\\20231110-2/'\n",
    "# root_path = 'Y:\\\\구어체_모음\\\\2023-11-10 구어체\\\\CW051\\\\20231110-2/'\n",
    "# root_path = 'Y:\\구어체_모음\\\\2023-11-13 구어체\\\\CW040\\\\20231113/'\n",
    "# root_path = f'Y:\\구어체_모음\\\\2023-11-13 구어체\\CW044\\\\20231113/'\n",
    "# root_path = f'Y:\\구어체_모음\\\\2023-11-13 구어체\\CW045\\\\20231113/'\n",
    "# root_path = f'Y:\\구어체_모음\\\\2023-11-13 구어체\\CW046\\\\20231113-1/'\n",
    "# root_path = f'Y:\\구어체_모음\\\\2023-11-13 구어체\\CW047\\\\20231113/'\n",
    "# root_path = f'Y:\\구어체_모음\\\\2023-11-13 구어체\\CW048\\\\20231113/'\n",
    "# root_path = f'Y:\\구어체_모음\\\\2023-11-13 구어체\\CW049\\\\20231113/'\n",
    "# root_path = f'Y:\\구어체_모음\\\\2023-11-13 구어체\\\\CW050\\\\20231113/'\n",
    "# root_path = f'Y:\\구어체_모음\\\\2023-11-13 구어체\\CW051\\\\20231113/'\n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-14 구어체\\\\CW040\\\\20231114/'\n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-14 구어체\\\\CW044\\\\20231114/'\n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-14 구어체\\\\CW045\\\\20231114/'\n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-14 구어체\\\\CW046\\\\20231114/'\n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-14 구어체\\\\CW047\\\\20231114/'   # CW047\t20231114 SEQ 1033 ~ 1080\n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-14 구어체\\\\CW048\\\\20231114/'   \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-14 구어체\\\\CW049\\\\20231114/'   \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-14 구어체\\\\CW050\\\\20231114/'   \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-14 구어체\\\\CW051\\\\20231114/'   \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-15 구어체\\\\CW051\\\\20231115/'   \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-20 구어체\\\\CW040\\\\20231120/'   \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-21 구어체\\\\CW051\\\\20231121/'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업자 작업경로(위가 너무 길어 분할)\n",
    "# root_path = r'Y:\\구어체_모음\\2023-11-22 구어체\\CW051\\20231122/'       # r : raw. 문자열 앞에 'r'을 붙이면 해당 문자열이 'raw string'으로 처리되어 이스케이프 문자를 해석하지 않고 그대로 문자열로 인식함!! -> 파일 경로 문자열에서 백슬래쉬를 이스케이프 문자로 처리하지 않고 그대로 사용할 수 있음.  \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-22 구어체\\\\CW051\\\\20231122/'   # f : f-string. Python 3.6 이상에서 도입된 문자열 포맷팅 방법. 문자열 안에서 변수나 표현식을 {}로 감싸 사용햘 수 있음.\n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-23 구어체\\\\CW049\\\\20231123/'  \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-24 구어체\\\\CW051\\\\20231124/'  \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-28 구어체\\\\CW049/'  \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-28 구어체\\\\CW051\\\\20231128/'  \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-30 구어체\\\\CW045/'  \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-30 구어체\\\\CW047\\\\20231130/'  # 46, 47, 50, 51\n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-12-01 구어체\\\\20231201/'  \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-12-04 구어체\\\\20231204/'  \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-12-05 구어체\\\\20231205/'  \n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-12-06 구어체/'  \n",
    "root_path = f'Y:\\\\구어체_모음\\\\2023-12-07 구어체/'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:\\구어체_모음\\2023-12-05 구어체\\20231205/ 20231205 CW047\n",
      "Connected to MySQL database\n",
      "file_name :  05_CW047_20231205_0001\n",
      "file_name :  05_CW047_20231205_0002\n",
      "file_name :  05_CW047_20231205_0003\n",
      "file_name :  05_CW047_20231205_0004\n",
      "file_name :  05_CW047_20231205_0005\n",
      "file_name :  05_CW047_20231205_0006\n",
      "file_name :  05_CW047_20231205_0007\n",
      "file_name :  05_CW047_20231205_0008\n",
      "file_name :  05_CW047_20231205_0009\n",
      "file_name :  05_CW047_20231205_0010\n",
      "file_name :  05_CW047_20231205_0011\n",
      "file_name :  05_CW047_20231205_0012\n",
      "file_name :  05_CW047_20231205_0013\n",
      "file_name :  05_CW047_20231205_0014\n",
      "file_name :  05_CW047_20231205_0015\n",
      "file_name :  05_CW047_20231205_0016\n",
      "file_name :  05_CW047_20231205_0017\n",
      "file_name :  05_CW047_20231205_0018\n",
      "file_name :  05_CW047_20231205_0019\n",
      "file_name :  05_CW047_20231205_0020\n",
      "file_name :  05_CW047_20231205_0021\n",
      "file_name :  05_CW047_20231205_0022\n",
      "file_name :  05_CW047_20231205_0023\n",
      "file_name :  05_CW047_20231205_0024\n",
      "file_name :  05_CW047_20231205_0025\n",
      "file_name :  05_CW047_20231205_0026\n",
      "file_name :  05_CW047_20231205_0027\n",
      "file_name :  05_CW047_20231205_0028\n",
      "file_name :  05_CW047_20231205_0029\n",
      "file_name :  05_CW047_20231205_0030\n",
      "file_name :  05_CW047_20231205_0031\n",
      "file_name :  05_CW047_20231205_0032\n",
      "file_name :  05_CW047_20231205_0033\n",
      "file_name :  05_CW047_20231205_0034\n",
      "file_name :  05_CW047_20231205_0035\n",
      "file_name :  05_CW047_20231205_0036\n",
      "file_name :  05_CW047_20231205_0037\n",
      "file_name :  05_CW047_20231205_0038\n",
      "file_name :  05_CW047_20231205_0039\n",
      "file_name :  05_CW047_20231205_0040\n",
      "file_name :  05_CW047_20231205_0041\n",
      "file_name :  05_CW047_20231205_0042\n",
      "file_name :  05_CW047_20231205_0043\n",
      "file_name :  05_CW047_20231205_0044\n",
      "file_name :  05_CW047_20231205_0045\n",
      "file_name :  05_CW047_20231205_0046\n",
      "file_name :  05_CW047_20231205_0047\n",
      "file_name :  05_CW047_20231205_0048\n",
      "file_name :  05_CW047_20231205_0049\n",
      "file_name :  05_CW047_20231205_0050\n",
      "file_name :  05_CW047_20231205_0051\n",
      "file_name :  05_CW047_20231205_0052\n",
      "file_name :  05_CW047_20231205_0053\n",
      "file_name :  05_CW047_20231205_0054\n",
      "file_name :  05_CW047_20231205_0055\n",
      "file_name :  05_CW047_20231205_0056\n",
      "file_name :  05_CW047_20231205_0057\n",
      "file_name :  05_CW047_20231205_0058\n",
      "file_name :  05_CW047_20231205_0059\n",
      "file_name :  05_CW047_20231205_0060\n",
      "file_name :  05_CW047_20231205_0061\n",
      "file_name :  05_CW047_20231205_0062\n",
      "file_name :  05_CW047_20231205_0063\n",
      "file_name :  05_CW047_20231205_0064\n",
      "file_name :  05_CW047_20231205_0065\n",
      "file_name :  05_CW047_20231205_0066\n",
      "file_name :  05_CW047_20231205_0067\n",
      "file_name :  05_CW047_20231205_0068\n",
      "file_name :  05_CW047_20231205_0069\n",
      "file_name :  05_CW047_20231205_0070\n",
      "file_name :  05_CW047_20231205_0071\n",
      "file_name :  05_CW047_20231205_0072\n",
      "file_name :  05_CW047_20231205_0073\n",
      "file_name :  05_CW047_20231205_0074\n",
      "file_name :  05_CW047_20231205_0075\n",
      "file_name :  05_CW047_20231205_0076\n",
      "file_name :  05_CW047_20231205_0077\n",
      "file_name :  05_CW047_20231205_0078\n",
      "file_name :  05_CW047_20231205_0079\n",
      "file_name :  05_CW047_20231205_0080\n",
      "file_name :  05_CW047_20231205_0081\n",
      "file_name :  05_CW047_20231205_0082\n",
      "file_name :  05_CW047_20231205_0083\n",
      "file_name :  05_CW047_20231205_0084\n",
      "file_name :  05_CW047_20231205_0085\n",
      "file_name :  05_CW047_20231205_0086\n",
      "file_name :  05_CW047_20231205_0087\n",
      "file_name :  05_CW047_20231205_0088\n",
      "file_name :  05_CW047_20231205_0089\n",
      "file_name :  05_CW047_20231205_0090\n",
      "file_name :  05_CW047_20231205_0091\n",
      "file_name :  05_CW047_20231205_0092\n",
      "file_name :  05_CW047_20231205_0093\n",
      "file_name :  05_CW047_20231205_0094\n",
      "file_name :  05_CW047_20231205_0095\n",
      "file_name :  05_CW047_20231205_0096\n",
      "file_name :  05_CW047_20231205_0097\n",
      "file_name :  05_CW047_20231205_0098\n",
      "file_name :  05_CW047_20231205_0099\n",
      "file_name :  05_CW047_20231205_0100\n",
      "file_name :  05_CW047_20231205_0101\n",
      "file_name :  05_CW047_20231205_0102\n",
      "file_name :  05_CW047_20231205_0103\n",
      "file_name :  05_CW047_20231205_0104\n",
      "file_name :  05_CW047_20231205_0105\n",
      "file_name :  05_CW047_20231205_0106\n",
      "file_name :  05_CW047_20231205_0107\n",
      "file_name :  05_CW047_20231205_0108\n",
      "file_name :  05_CW047_20231205_0109\n",
      "file_name :  05_CW047_20231205_0110\n",
      "file_name :  05_CW047_20231205_0111\n",
      "file_name :  05_CW047_20231205_0112\n",
      "file_name :  05_CW047_20231205_0113\n",
      "file_name :  05_CW047_20231205_0114\n",
      "file_name :  05_CW047_20231205_0115\n",
      "file_name :  05_CW047_20231205_0116\n",
      "file_name :  05_CW047_20231205_0117\n",
      "file_name :  05_CW047_20231205_0118\n",
      "file_name :  05_CW047_20231205_0119\n",
      "file_name :  05_CW047_20231205_0120\n",
      "file_name :  05_CW047_20231205_0121\n",
      "file_name :  05_CW047_20231205_0122\n",
      "file_name :  05_CW047_20231205_0123\n",
      "file_name :  05_CW047_20231205_0124\n",
      "file_name :  05_CW047_20231205_0125\n",
      "file_name :  05_CW047_20231205_0126\n",
      "file_name :  05_CW047_20231205_0127\n",
      "file_name :  05_CW047_20231205_0128\n",
      "file_name :  05_CW047_20231205_0129\n",
      "file_name :  05_CW047_20231205_0130\n",
      "file_name :  05_CW047_20231205_0131\n",
      "file_name :  05_CW047_20231205_0132\n",
      "file_name :  05_CW047_20231205_0133\n",
      "file_name :  05_CW047_20231205_0134\n",
      "file_name :  05_CW047_20231205_0135\n",
      "file_name :  05_CW047_20231205_0136\n",
      "file_name :  05_CW047_20231205_0137\n",
      "file_name :  05_CW047_20231205_0138\n",
      "file_name :  05_CW047_20231205_0139\n",
      "file_name :  05_CW047_20231205_0140\n",
      "file_name :  05_CW047_20231205_0141\n",
      "file_name :  05_CW047_20231205_0142\n",
      "file_name :  05_CW047_20231205_0143\n",
      "file_name :  05_CW047_20231205_0144\n",
      "file_name :  05_CW047_20231205_0145\n",
      "file_name :  05_CW047_20231205_0146\n",
      "file_name :  05_CW047_20231205_0147\n",
      "file_name :  05_CW047_20231205_0148\n",
      "file_name :  05_CW047_20231205_0149\n",
      "file_name :  05_CW047_20231205_0150\n",
      "20231205_CW047.xlsx 완료! \n",
      "Disconnected from MySQL database \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 작업자 폴더 하나씩 잡아서 처리\n",
    "\n",
    "# 처리\n",
    "# JOB_YMD = '20231130'\n",
    "# WORKER_ID = os.path.basename(root_path[:-1])\n",
    "\n",
    "JOB_YMD = os.path.basename(root_path[:-1])  # 마지막 '/'을 뺀 디렉토리 경로를 넣어줘야 함.  JOB_YMD : 2023-12-06 구어체\n",
    "# JOB_YMD = JOB_YMD[:4] + JOB_YMD[5:7] + JOB_YMD[8:10]\n",
    "\n",
    "# WORKER_ID = os.path.basename(root_path[:-10])   # root_path가 문자열형이므로 \\\\ -> /로 처리되므로 1개로 생각! \n",
    "WORKER_ID = 'CW047'\n",
    "print(root_path, JOB_YMD, WORKER_ID)\n",
    "\n",
    "files = [file for file in os.listdir(root_path) if not os.path.basename(os.path.join(root_path, file)).startswith('~$') \n",
    "         and (os.path.basename(os.path.join(root_path, file)).endswith('.docx') or os.path.basename(os.path.join(root_path, file)).endswith('.xlsx'))]\n",
    "\n",
    "WORK_CNT = len(files) - 1    # docx 파일 개수\n",
    "        \n",
    "# 테이블이 정상적으로 CREATE 된 경우\n",
    "# if CREATE_TABLE:\n",
    "if True:\n",
    "    \n",
    "    try:   \n",
    "        db = pymysql.connect(host=mysql_host,port=mysql_port,user=mysql_user,passwd=mysql_password,db=mysql_database)\n",
    "        cursor = db.cursor(pymysql.cursors.DictCursor)\n",
    "        print(\"Connected to MySQL database\")\n",
    "        \n",
    "        excel_bulk_insert_datas = []\n",
    "        file_bulk_insert_datas = []\n",
    "        # docx_bulk_insert_datas = []\n",
    "            \n",
    "        for file in files:\n",
    "\n",
    "            # print(f'{file} 처리 시작')\n",
    "            # print(f'\\tJOB_YMD : {JOB_YMD}')\n",
    "            # print(f'\\tWORKER_ID : {WORKER_ID}')\n",
    "            # print(f'\\tWORK_CNT : {WORK_CNT}')\n",
    "            \n",
    "            file_path = root_path+file\n",
    "            \n",
    "            # 파일 정보 가져오기\n",
    "            FILE_NAME, FILE_SIZE, file_creation_time, file_modification_time = get_file_info(file_path)\n",
    "\n",
    "            # 시간을 원하는 형식으로 변환\n",
    "            FILE_CREATETIME = format_time(file_creation_time)\n",
    "            FILE_CHANG_TIME = format_time(file_modification_time)\n",
    "\n",
    "            # 단어수 업데이트 할 때\n",
    "            if file_path.lower().endswith(\".docx\"):\n",
    "                doc = docx.Document(file_path)\n",
    "                SEQ = 1\n",
    "                WORD_COUNT = 0\n",
    "                docx_bulk_insert_datas = []\n",
    "                \n",
    "                for paragraph in doc.paragraphs:\n",
    "                    WORD_COUNT += len(paragraph.text.split())   # 문서 내 단어 수 세기 \n",
    "\n",
    "                    texts = paragraph.text.split('\\n')\n",
    "                    texts = [txts for txts in texts if not txts == '' ]           # 빈공백으로만 있는 텍스트 제거\n",
    "                    texts = [txts for txts in texts if not txts.strip() == '' ]   # 앞뒤 공백 자른 txts가 ''인 것 제거\n",
    "                    \n",
    "                    # '\\n' 별로 저장할 때           \n",
    "                    if texts:\n",
    "                        for text in texts:\n",
    "                            text = text.replace(\"'\", \"''\")\n",
    "                            text = text.replace(\"\\u00A0\", \" \")    # strip()이 걸러내지 못하는 &nbsp 제거\n",
    "                            text = text.replace(\"\\uFEFF\", \" \")    # HTML 코드(&#65279;) 제거\n",
    "                            text = text.replace('\\t', ' ')\n",
    "                            text = text.replace('\\xa0', ' ')\n",
    "                            text = text.strip()     # 앞 뒤 공백 제거\n",
    "                            # print(f'{SEQ} : {text} \\n')\n",
    "                            \n",
    "                            # 벌크에 넣기\n",
    "                            docx_bulk_insert_datas.append((FILE_NAME, SEQ, text))\n",
    "\n",
    "                            # text line_seq 증가\n",
    "                            SEQ += 1\n",
    "                    \n",
    "                sql = ''\n",
    "                sql = 'SAVEPOINT a'\n",
    "                cursor.execute(sql)\n",
    "                \n",
    "                # 한 파일당 인서트             \n",
    "                # .docx 파일 정보 인서트\n",
    "                sql = \"\"\n",
    "                sql =  sql + f\" INSERT INTO {file_tb} \"\n",
    "                sql = sql + \" (workymd, worker_id, workcnt, file_name, file_size, file_createtime, file_chang_time, word_count) \"\n",
    "                sql = sql + f\" VALUES ('{JOB_YMD}', '{WORKER_ID}', '{WORK_CNT}', '{FILE_NAME}', '{FILE_SIZE}', '{FILE_CREATETIME}', '{FILE_CHANG_TIME}', '{WORD_COUNT}') \"\n",
    "                cursor.execute(sql)\n",
    "                # db.commit()\n",
    "                \n",
    "                # .docx 문서 문단 인서트\n",
    "                sql = \"\"\n",
    "                sql = sql + f\" INSERT INTO {docx_tb} (FILE_NAME, SEQ, FILE_TXT) VALUES (%s, %s, %s)\"\n",
    "                cursor.executemany(sql, docx_bulk_insert_datas)\n",
    "                # db.commit()\n",
    "                \n",
    "                print(\"file_name : \", FILE_NAME)\n",
    "                # print(f\"{file} 인서트 완료\")\n",
    "\n",
    "\n",
    "            if file_path.endswith(\".xlsx\"):\n",
    "                \n",
    "                # 엑셀에서 데이터 GET\n",
    "                # bulk_insert_datas = []\n",
    "                datas = []\n",
    "                read_flag = False\n",
    "\n",
    "                data_frame = pd.read_excel(file_path, engine='openpyxl')\n",
    "                datas.append(data_frame)\n",
    "\n",
    "                # chunk_size = 300  # 원하는 청크 크기\n",
    "                \n",
    "                for df in datas:\n",
    "                    for index, row in df.iterrows():\n",
    "                        # print('row',row)\n",
    "                        # print('row[0]',row[0])\n",
    "                    \n",
    "                        if(str(row.iloc[0]) == '1'):\n",
    "                            read_flag = True\n",
    "                        \n",
    "                        if(str(row.iloc[0]) == ''):\n",
    "                            read_flag = False\n",
    "                        \n",
    "                        if(read_flag):\n",
    "                            SEQ = int(row.iloc[0])\n",
    "                            PUB_YMD = str(row.iloc[3]).strip()\n",
    "                            WTR_KR = str(row.iloc[4]).replace(\"'\", \"''\").strip()\n",
    "                            WTR_VN = str(row.iloc[5]).replace(\"'\", \"''\").strip()\n",
    "                            CTR_KR = str(row.iloc[6]).replace(\"'\", \"''\").strip()\n",
    "                            CTR_VN = str(row.iloc[7]).replace(\"'\", \"''\").strip()\n",
    "                            ORG_TYP = str(row.iloc[8]).strip()\n",
    "                            DAT_SRC = str(row.iloc[9]).replace(\"'\", \"''\").strip()   # 작은따옴표를 두 번 사용하여 이스케이프\n",
    "                            DAT_TYP = str(row.iloc[10]).strip()\n",
    "                            TOPIC_KR = str(row.iloc[11]).strip()\n",
    "                            TOPIC_VN = str(row.iloc[12]).strip()\n",
    "                            TITLE = str(row.iloc[13]).replace(\"'\", \"''\").strip()  # 작은따옴표를 두 번 사용하여 이스케이프\n",
    "                            COL_PK = str(row.iloc[14]).split('.')[0]\n",
    "                            # DOC_STYLE = '구어체' if '구어체 여부' in str(row.iloc[15]).strip() else '문어체'\n",
    "                            DOC_STYLE = '구어체'\n",
    "                            # print(SEQ, COL_PK, PUB_YMD, TITLE)\n",
    "                                                        \n",
    "                            # {excel_tb}에 인서트\n",
    "                            sql = \"\"\n",
    "                            sql = sql + f\" INSERT INTO {excel_tb} \"\n",
    "                            sql = sql + \" (COL_PK, SEQ, WORKER_ID, JOB_YMD, PUB_YMD, WTR_KR, WTR_VN, CTR_KR, CTR_VN, ORG_TYP, DAT_SRC, DAT_TYP, TOPIC_KR, TOPIC_VN, TITLE, FILE_NAME, DOC_STYLE) \"\n",
    "                            sql = sql + f\" VALUES ('{COL_PK}', '{SEQ}', '{WORKER_ID}', '{JOB_YMD}', '{PUB_YMD}', '{WTR_KR}', '{WTR_VN}', '{CTR_KR}', '{CTR_VN}', '{ORG_TYP}', '{DAT_SRC}', '{DAT_TYP}', '{TOPIC_KR}', '{TOPIC_VN}', '{TITLE}', '{COL_PK}', '{DOC_STYLE}') \"\n",
    "                            cursor.execute(sql)\n",
    "                            # db.commit()\n",
    "                print(f'{file} 완료! ')\n",
    "        \n",
    "        # for문 다 돈 후 db 영구반영         \n",
    "        db.commit() \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at preceeding {file}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "        # sql = ''\n",
    "        # sql = 'rollback to a'\n",
    "        # cursor.execute(sql)\n",
    "        \n",
    "        sys.exit()\n",
    "\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if db:\n",
    "            db.close()\n",
    "            print(\"Disconnected from MySQL database \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업자 폴더 자동으로 잡아서 처리\n",
    "\n",
    "# 한 작업자가 작업한 양을 저장할 배열 초기화\n",
    "excel_bulk_insert_datas = []\n",
    "file_bulk_insert_datas = []\n",
    "docx_bulk_insert_datas = []\n",
    "\n",
    "JOB_YMD = os.path.basename(root_path[:-1])  # 마지막 '/'을 뺀 디렉토리 경로를 넣어줘야 함.  JOB_YMD : 2023-12-06 구어체\n",
    "JOB_YMD = JOB_YMD[:4] + JOB_YMD[5:7] + JOB_YMD[8:10]\n",
    "\n",
    "# 기록\n",
    "now = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "sys.stdout = open(f'C:\\\\YJ\\\\Python_print/{now}.txt','w', encoding=\"utf-8\")  # 현재 위치에 파일 생성, 기록\n",
    "\n",
    "try:\n",
    "    #  MySQL 데이터베이스에 연결\n",
    "    db = pymysql.connect(host=mysql_host,port=mysql_port,user=mysql_user,passwd=mysql_password,db=mysql_database)   \n",
    "    cursor = db.cursor(pymysql.cursors.DictCursor)  # 데이터베이스와 상호작용하기 위한 커서(cursor)를 생성\n",
    "    print(\"Connected to MySQL database\")\n",
    "    \n",
    "    worker_folders = os.listdir(root_path)\n",
    "    for worker in worker_folders:\n",
    "        WORKER_ID = worker\n",
    "        \n",
    "        if len(WORKER_ID) > 5 :\n",
    "            # 작업자 폴더 길이가 5를 초과하면 해당 파일 처리를 건너뜀.(자동화로 처리된 파일)\n",
    "            continue\n",
    "        \n",
    "        worker_path = os.path.join(root_path, worker)   # Y:\\구어체_모음\\2023-12-06 구어체\\CW040\n",
    "        \n",
    "        # 작업자 폴더 하위에 JOB_YMD 폴더가 따로 존재하는 경우(ex. Y:\\구어체_모음\\2023-11-22 구어체\\CW040\\20231122\\.docx)\n",
    "        # job_folder = os.listdir(worker_path)[0]  # 가장 첫번째 폴더 가져옴\n",
    "        # job_folder_path = os.path.join(worker_path, job_folder)\n",
    "        \n",
    "        # JOB_YMD = os.path.basename(job_folder_path) # 가장 마지막 경로명 추출\n",
    "        # WORKER_ID = os.path.dirname(job_folder_path)    # 가장 마지막 경로명의 상위 경로 추출 (Y:/구어체_모음/2023-11-15 구어체/CW040)\n",
    "        \n",
    "        print(JOB_YMD, WORKER_ID + ' 처리 시작')\n",
    "        \n",
    "        # 작업자의 .docx, .xlsx에 접근\n",
    "        files = [file for file in os.listdir(worker_path) if not os.path.basename(os.path.join(worker_path, file)).startswith('~$') \n",
    "            and (os.path.basename(os.path.join(worker_path, file)).endswith('.docx') or os.path.basename(os.path.join(worker_path, file)).endswith('.xlsx'))]\n",
    "\n",
    "        WORK_CNT = len(files) - 1    # docx 파일 개수\n",
    "                \n",
    "        # 테이블이 정상적으로 CREATE 된 경우\n",
    "        # if CREATE_TABLE:\n",
    "        if True:\n",
    "            \n",
    "            # 초기화\n",
    "            excel_bulk_insert_datas = []\n",
    "            file_bulk_insert_datas = []\n",
    "            docx_bulk_insert_datas = []\n",
    "                \n",
    "            for file in files:\n",
    "                \n",
    "                file_path = os.path.join(worker_path, file)\n",
    "            \n",
    "                # .docx 처리\n",
    "                if file_path.lower().endswith(\".docx\"):\n",
    "                    \n",
    "                    # {file_db} \n",
    "                    # 파일 정보 가져오기\n",
    "                    FILE_NAME, FILE_SIZE, file_creation_time, file_modification_time = get_file_info(file_path)\n",
    "\n",
    "                    # 시간을 원하는 형식으로 변환\n",
    "                    FILE_CREATETIME = format_time(file_creation_time)\n",
    "                    FILE_CHANG_TIME = format_time(file_modification_time)\n",
    "                    \n",
    "                    # {docx_tb} 처리\n",
    "                    doc = docx.Document(file_path)\n",
    "                    SEQ = 1\n",
    "                    WORD_COUNT = 0\n",
    "                    # docx_bulk_insert_datas = []\n",
    "                    \n",
    "                    for paragraph in doc.paragraphs:\n",
    "                        WORD_COUNT += len(paragraph.text.split())   # 문서 내 단어 수 세기 \n",
    "\n",
    "                        texts = paragraph.text.split('\\n')\n",
    "                        texts = [txts for txts in texts if not txts == '' ]           # 빈공백으로만 있는 텍스트 제거\n",
    "                        texts = [txts for txts in texts if not txts.strip() == '' ]   # 앞뒤 공백 자른 txts가 ''인 것 제거\n",
    "                        \n",
    "                        # '\\n' 별로 저장할 때           \n",
    "                        if texts:\n",
    "                            for text in texts:\n",
    "                                text = text.replace(\"'\", \"''\")         # 디비 인서트를 위한 처리\n",
    "                                text = text.replace(\"\\u00A0\", \" \")    # strip()이 걸러내지 못하는 &nbsp 제거\n",
    "                                text = text.replace(\"\\uFEFF\", \" \")    # HTML 코드(&#65279;) 제거\n",
    "                                text = text.replace('\\t', ' ')\n",
    "                                text = text.replace('\\xa0', ' ')\n",
    "                                text = text.strip()     # 앞 뒤 공백 제거\n",
    "                                # print(f'{SEQ} : {text} \\n')\n",
    "                                \n",
    "                                # 벌크에 넣기\n",
    "                                docx_bulk_insert_datas.append((FILE_NAME, SEQ, text))\n",
    "\n",
    "                                # text line_seq 증가\n",
    "                                SEQ += 1\n",
    "                    \n",
    "                    file_bulk_insert_datas.append((JOB_YMD, WORKER_ID, WORK_CNT, FILE_NAME, FILE_SIZE, FILE_CREATETIME, FILE_CHANG_TIME, WORD_COUNT))\n",
    "                    print(f'{FILE_NAME} fin')\n",
    "\n",
    "                elif file_path.endswith(\".xlsx\"):\n",
    "                    \n",
    "                    # 엑셀에서 데이터 GET\n",
    "                    # bulk_insert_datas = []\n",
    "                    datas = []\n",
    "                    read_flag = False\n",
    "\n",
    "                    data_frame = pd.read_excel(file_path, engine='openpyxl')\n",
    "                    datas.append(data_frame)\n",
    "\n",
    "                    # chunk_size = 300  # 원하는 청크 크기\n",
    "                    \n",
    "                    for df in datas:\n",
    "                        for index, row in df.iterrows():\n",
    "                            # print('row',row)\n",
    "                            # print('row[0]',row[0])\n",
    "                        \n",
    "                            if(str(row.iloc[0]) == '1'):\n",
    "                                read_flag = True\n",
    "                            \n",
    "                            if(str(row.iloc[0]) == ''):\n",
    "                                read_flag = False\n",
    "                            \n",
    "                            if(read_flag):\n",
    "                                SEQ = int(row.iloc[0])\n",
    "                                PUB_YMD = str(row.iloc[3]).strip()\n",
    "                                WTR_KR = str(row.iloc[4]).replace(\"'\", \"''\").strip()\n",
    "                                WTR_VN = str(row.iloc[5]).replace(\"'\", \"''\").strip()\n",
    "                                CTR_KR = str(row.iloc[6]).replace(\"'\", \"''\").strip()\n",
    "                                CTR_VN = str(row.iloc[7]).replace(\"'\", \"''\").strip()\n",
    "                                ORG_TYP = str(row.iloc[8]).strip()\n",
    "                                DAT_SRC = str(row.iloc[9]).replace(\"'\", \"''\").strip()   # 작은따옴표를 두 번 사용하여 이스케이프\n",
    "                                DAT_TYP = str(row.iloc[10]).strip()\n",
    "                                TOPIC_KR = str(row.iloc[11]).strip()\n",
    "                                TOPIC_VN = str(row.iloc[12]).strip()\n",
    "                                TITLE = str(row.iloc[13]).replace(\"'\", \"''\").strip()  # 작은따옴표를 두 번 사용하여 이스케이프\n",
    "                                COL_PK = str(row.iloc[14]).split('.')[0]\n",
    "                                # DOC_STYLE = '구어체' if '구어체 여부' in str(row.iloc[15]).strip() else '문어체'\n",
    "                                DOC_STYLE = '구어체'\n",
    "                                # print(SEQ, COL_PK, PUB_YMD, TITLE)\n",
    "                                                            \n",
    "                                # {excel_tb}에 인서트\n",
    "                                excel_bulk_insert_datas.append((COL_PK, SEQ, WORKER_ID, JOB_YMD, PUB_YMD, WTR_KR, \n",
    "                                                                WTR_VN, CTR_KR, CTR_VN, ORG_TYP, DAT_SRC, DAT_TYP, \n",
    "                                                                TOPIC_KR, TOPIC_VN, TITLE, COL_PK, DOC_STYLE))\n",
    "                                \n",
    "                    print(f'{file} fin')\n",
    "                \n",
    "            # 작업자별로 인서트    \n",
    "            sql = ''\n",
    "            sql = f'SAVEPOINT {WORKER_ID}'\n",
    "            cursor.execute(sql)\n",
    "            \n",
    "            # {file_tb} 인서트\n",
    "            sql = \"\"\n",
    "            sql = sql + f\" INSERT INTO {file_tb} (workymd, worker_id, workcnt, file_name, file_size, file_createtime, file_chang_time, word_count)\"\n",
    "            sql = sql + \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "            cursor.executemany(sql, file_bulk_insert_datas)\n",
    "            # db.commit()\n",
    "            \n",
    "            # {docx_tb} 300개씩 인서트\n",
    "            for i in range(0, len(docx_bulk_insert_datas), 300):\n",
    "                batch = docx_bulk_insert_datas[i:i+300]\n",
    "                \n",
    "                sql = \"\"\n",
    "                sql = sql + f\" INSERT INTO {docx_tb} (FILE_NAME, SEQ, FILE_TXT)\"\n",
    "                sql = sql + \" VALUES (%s, %s, %s)\"\n",
    "                cursor.executemany(sql, batch)\n",
    "                # db.commit()   \n",
    "                # print(f'{len(batch)}')\n",
    "            \n",
    "            # {excel_tb} 인서트\n",
    "            sql = \"\"\n",
    "            sql = sql + f\" INSERT INTO {excel_tb} \"\n",
    "            sql = sql + \" (COL_PK, SEQ, WORKER_ID, JOB_YMD, PUB_YMD, WTR_KR, WTR_VN, CTR_KR, CTR_VN, ORG_TYP, DAT_SRC, DAT_TYP, TOPIC_KR, TOPIC_VN, TITLE, FILE_NAME, DOC_STYLE) \"\n",
    "            sql = sql + \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s) \"\n",
    "            cursor.executemany(sql, excel_bulk_insert_datas)\n",
    "            # db.commit()\n",
    "            \n",
    "            # 3개의 테이블 모두 execute 후 db 영구반영         \n",
    "            db.commit()    \n",
    "            \n",
    "            print(f\"{WORKER_ID} FIN\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error at preceeding {WORKER_ID} files\")\n",
    "    print(f\"Error: {e}\")\n",
    "    \n",
    "    sql = ''\n",
    "    sql = f'rollback to {WORKER_ID}'\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    sys.exit()\n",
    "\n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if db:\n",
    "        db.close()\n",
    "        print(\"Disconnected from MySQL database \\n\")\n",
    "\n",
    "if sys:\n",
    "    sys.stdout.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
