{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import docx\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from pymysql import MySQLError\n",
    "\n",
    "def get_file_info(file_path):\n",
    "    file_size = os.path.getsize(file_path)                  # 파일 크기를 바이트 단위로 가져오기 \n",
    "    file_creation_time = os.path.getctime(file_path)        # 파일 생성일자를 가져오기\n",
    "    file_modification_time = os.path.getmtime(file_path)    # 파일 최종 수정일자를 가져오기\n",
    "    # file_name = os.path.basename(file_path)                 # 파일명 추출\n",
    "    file_name, file_extension = os.path.splitext(os.path.basename(file_path))                 # 확장명 뺀 파일명 추출\n",
    "    \n",
    "    return file_name, file_size, file_creation_time, file_modification_time\n",
    "\n",
    "def format_time(timestamp):\n",
    "    dt_object = datetime.fromtimestamp(timestamp)               # 에포크 시간을 datetime 객체로 변환\n",
    "    formatted_time = dt_object.strftime('%Y-%m-%d %H:%M:%S')    # 원하는 형식으로 시간을 포맷팅\n",
    "    \n",
    "    return formatted_time\n",
    "\n",
    "def count_words_docx(file_path):\n",
    "    total_words = 0\n",
    "    doc = docx.Document(file_path)\n",
    "\n",
    "    for paragraph in doc.paragraphs:\n",
    "        total_words += len(paragraph.text.split())   # 문서 내 단어 수 세기 \n",
    "\n",
    "    return total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL 연결 정보\n",
    "mysql_host = '172.30.1.36'\n",
    "mysql_port = 13333\n",
    "mysql_user = 'vnc'\n",
    "mysql_password = 'vnc'\n",
    "mysql_database = 'vnc'\n",
    "\n",
    "\n",
    "excel_tb = 'load_vnc_org_lst_sim_20231130_05'\n",
    "file_tb = 'load_vnc_file_list_sim_20231130_05'\n",
    "docx_tb = 'load_vnc_file_docx_sim_20231130_05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# org 정보\n",
    "JOB_YMD = '20231130'\n",
    "WORKER_ID = 'CW055'\n",
    "PUB_YMD = ''\n",
    "WTR_KR = '구텐베르크 프로젝트'\n",
    "WTR_VN = 'Dự án Gutenberg'\n",
    "CTR_KR = ''\n",
    "CTR_VN = ''\n",
    "ORG_TYP = 'html'\n",
    "DAT_TYP = '문학'\n",
    "TOPIC_KR = '문화/역사/예술'\n",
    "TOPIC_VN = 'VĂN HÓA/ LỊCH SỬ/ NGHỆ THUẬT'\n",
    "TITLE = ''\n",
    "DOC_STYLE = '구어체'\n",
    "TOPIC_CD = '05'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 파일 경로\n",
    "# root_path = 'Y:/_구어체_학교이야기/'                             # CW047 20231114 SEQ 1 ~ 54\n",
    "# root_path = 'Y:/_구어체_아동소설/'                                # CW047 20231114 SEQ 55 ~ 239 \n",
    "# root_path = 'Y:\\\\구어체_모음/2023-11-14 구어체\\\\자동화2/'        # CW047 20231114 SEQ 240 ~ 809\n",
    "# root_path = 'Y:\\\\구어체_모음\\\\2023-11-14 구어체\\\\자동화2_추가/'     # CW047 20231114 SEQ 810 ~ 1032\n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-22 구어체\\\\자동화3_CW055/'     # CW055 20231122 SEQ 1 ~ 131\n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-22 구어체\\\\자동화4_CW056/'     # CW056 20231122 SEQ 1 ~ 1032\n",
    "# root_path = f'Y:\\\\구어체_모음\\\\2023-11-28 구어체\\\\자동화_en_CW055/'     # CW056 20231128 SEQ 1 ~ ?\n",
    "root_path = r'Y:\\구어체_모음\\2023-11-30 구어체\\자동화27_CW055/'     # CW055 20231130 SEQ 1 ~ 182\n",
    "\n",
    "file_list = os.listdir(root_path)\n",
    "file_list = [file for file in file_list if not file.split('.')[1] == 'xlsx' and len(file) > 10]\n",
    "\n",
    "# file = 'httpswww.gutenberg.orgcacheepub952pg952.txt'\n",
    "\n",
    "try:\n",
    "    db = pymysql.connect(host=mysql_host,port=mysql_port,user=mysql_user,passwd=mysql_password,db=mysql_database)\n",
    "    cursor = db.cursor(pymysql.cursors.DictCursor)\n",
    "    print(\"Connected to MySQL database\")\n",
    "    \n",
    "    # 세이브포인트\n",
    "    sql = ''\n",
    "    sql = 'SAVEPOINT a'\n",
    "    cursor.execute(sql)\n",
    "                \n",
    "    for idx, file in enumerate(file_list, start=0):\n",
    "    # if True:\n",
    "        \n",
    "        # FILE_NAME을 위한 SEQ\n",
    "        ORG_SEQ = idx + 1\n",
    "        # ORG_SEQ = 1\n",
    "        FILE_NAME = TOPIC_CD + '_' + WORKER_ID + '_' + JOB_YMD + '_' + str(ORG_SEQ).rjust(4, '0')\n",
    "        \n",
    "        # print(f\"{file} : {FILE_NAME}\")\n",
    "        \n",
    "        # FILE_LIST에 들어갈 정보\n",
    "        txt_name, FILE_SIZE, file_creation_time, file_modification_time = get_file_info(os.path.join(root_path, file))\n",
    "        \n",
    "        # 시간을 원하는 형식으로 변환\n",
    "        FILE_CREATETIME = format_time(file_creation_time)\n",
    "        FILE_CHANG_TIME = format_time(file_modification_time)\n",
    "\n",
    "        DAT_SRC = txt_name\n",
    "        DAT_SRC = DAT_SRC.replace(\"'\", \"''\")\n",
    "        \n",
    "        docx_bulk_insert_datas = []\n",
    "        chunk_size = 300\n",
    "        \n",
    "        # 파일 열기 (기본적으로는 읽기 모드인 'r' 모드로 열림)\n",
    "        with open(os.path.join(root_path, file), 'r', encoding='utf-8') as txt:\n",
    "            \n",
    "            # 파일의 내용 읽기\n",
    "            # file_content = txt.read()\n",
    "            \n",
    "            # paragraphs = txt.read().split('\\n\\n')  # 빈 줄을 기준으로 문단 나누기\n",
    "\n",
    "            lines = txt.read().split('\\n')\n",
    "            \n",
    "            # 빈 문장 제거\n",
    "            lines = [line for line in lines if not line == '' ]           # 빈공백으로만 있는 텍스트 제거\n",
    "            lines = [line for line in lines if not line.strip() == '' ]\n",
    "            \n",
    "            start_index = 0\n",
    "            end_index = 0\n",
    "            \n",
    "            # 한줄 씩 순회\n",
    "            for i, line in enumerate(lines, start=0):\n",
    "                \n",
    "                if str(line).startswith('Tiêu đề:'):\n",
    "                    TITLE = str(line)[9:].strip()\n",
    "                    TITLE = TITLE.replace(\"'\", \"''\")\n",
    "                \n",
    "                if str(line).startswith('Tác giả:'):\n",
    "                    CTR_KR = str(line)[9:].strip()\n",
    "                    CTR_KR = CTR_KR.replace(\"'\", \"''\")\n",
    "                    CTR_VN = CTR_KR\n",
    "                    \n",
    "                if str(line).startswith('Ngày phát hành:'):\n",
    "                    PUB_YMD = str(line)[16:].strip()\n",
    "                    # PUB_YMD = str(line).split()[8] + str(line).split()[6].rjust(2, '0') + str(line).split()[4].rjust(2, '0')\n",
    "                \n",
    "                if str(line).startswith('*** Bắt đầu'):\n",
    "                # if str(line).startswith('Chương i'):\n",
    "                    start_index = i\n",
    "                \n",
    "                if str(line).startswith('*** Kết thúc'):\n",
    "                    end_index = i\n",
    "                    \n",
    "            # print(f\"{PUB_YMD}, {TITLE}, {CTR_KR}\")\n",
    "            # print(f\"{start_index}, {end_index}\")\n",
    "            WORD_COUNT = 0\n",
    "            DOCX_SEQ = 1\n",
    "            \n",
    "            lines = lines[start_index + 3 : end_index - 1]  \n",
    "            \n",
    "            # 각 문단에 대한 처리 수행\n",
    "            for i, line in enumerate(lines):\n",
    "                \n",
    "                # if i == end_index:\n",
    "                #     break\n",
    "                        \n",
    "                WORD_COUNT += len(line.split(' '))   # 문서 내 단어 수 세기 \n",
    "                \n",
    "                # '\\n' 별로 저장할 때           \n",
    "                line = line.replace(\"'\", \"''\")\n",
    "                line = line.replace(\"\\u00A0\", \" \")    # strip()이 걸러내지 못하는 &nbsp 제거\n",
    "                line = line.replace(\"\\uFEFF\", \" \")    # HTML 코드(&#65279;) 제거\n",
    "                line = line.replace('\\t', ' ')\n",
    "                line = line.replace('\\xa0', ' ')\n",
    "                line = line.strip()     # 앞 뒤 공백 제거\n",
    "                # print(f'{DOCX_SEQ}번, {WORD_COUNT} : {line} \\n')\n",
    "                    \n",
    "                # 벌크에 넣기\n",
    "                docx_bulk_insert_datas.append((FILE_NAME, DOCX_SEQ, line))\n",
    "\n",
    "                # text line_seq 증가\n",
    "                DOCX_SEQ += 1   \n",
    "          \n",
    "        # org 테이블\n",
    "        sql = \"\"\n",
    "        sql = sql + f\" INSERT INTO {excel_tb} \"\n",
    "        sql = sql + \" (COL_PK, SEQ, WORKER_ID, JOB_YMD, PUB_YMD, WTR_KR, WTR_VN, CTR_KR, CTR_VN, ORG_TYP, DAT_SRC, DAT_TYP, TOPIC_KR, TOPIC_VN, TITLE, FILE_NAME, DOC_STYLE) \"\n",
    "        sql = sql + f''' VALUES ('{FILE_NAME}', '{ORG_SEQ}', '{WORKER_ID}', '{JOB_YMD}', '{PUB_YMD}', '{WTR_KR}', \n",
    "                                '{WTR_VN}', '{CTR_KR}', '{CTR_VN}', '{ORG_TYP}', '{DAT_SRC}', '{DAT_TYP}', '{TOPIC_KR}', '{TOPIC_VN}', '{TITLE}', '{FILE_NAME}', '{DOC_STYLE}') '''\n",
    "        cursor.execute(sql)\n",
    "        # db.commit()\n",
    "        \n",
    "        # file_list 테이블\n",
    "        sql = \"\"\n",
    "        sql =  sql + f\" INSERT INTO {file_tb} \"\n",
    "        sql = sql + \" (workymd, worker_id, workcnt, file_name, file_size, file_createtime, file_chang_time, word_count, org_file_name) \"\n",
    "        sql = sql + f\"\"\" VALUES ('{JOB_YMD}', '{WORKER_ID}', '55' , '{FILE_NAME}', '{FILE_SIZE}', '{FILE_CREATETIME}', '{FILE_CHANG_TIME}', '{WORD_COUNT}', '{root_path}{file}') \"\"\"\n",
    "        cursor.execute(sql)\n",
    "        # db.commit()\n",
    "        \n",
    "        # docx 테이블\n",
    "        for i in range(0, len(docx_bulk_insert_datas), chunk_size):\n",
    "            batch = docx_bulk_insert_datas[i:i+chunk_size]\n",
    "            # print(batch)\n",
    "            \n",
    "            sql = \"\"\n",
    "            sql = sql + f\" INSERT INTO {docx_tb} \"\n",
    "            sql = sql + \" (FILE_NAME, SEQ, FILE_TXT) \"\n",
    "            sql = sql + \" VALUES (%s, %s, %s)\"\n",
    "            cursor.executemany(sql, batch)\n",
    "            # db.commit()\n",
    "            # print(f'{len(batch)}개 저장완료')   \n",
    "    \n",
    "        print(f\"{file} : {FILE_NAME} 처리.\") \n",
    "    \n",
    "    db.commit()\n",
    "\n",
    "except MySQLError as e:\n",
    "    print(f\"MySQLError at {file} : {FILE_NAME}\")\n",
    "    print(f\"MySQLError: {e}\")\n",
    "    \n",
    "    sql = ''\n",
    "    sql = 'rollback to a'\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    # sql = ''\n",
    "    # sql = sql + f'DELETE FROM {excel_tb} WHERE WORKER_ID = \"{WORKER_ID}\" AND JOB_YMD = \"{JOB_YMD}\"'\n",
    "    # cursor.execute(sql)\n",
    "    # db.commit()\n",
    "    \n",
    "    # sql = ''\n",
    "    # sql = sql + f'DELETE FROM {file_tb} WHERE WORKER_ID = \"{WORKER_ID}\" AND WORKYMD = \"{JOB_YMD}\"'\n",
    "    # cursor.execute(sql)\n",
    "    # db.commit()\n",
    "    \n",
    "    # sql = ''\n",
    "    # sql = sql + f'DELETE FROM {docx_tb} WHERE FILE_NAME LIKE \"%{WORKER_ID}_{JOB_YMD}%\"'\n",
    "    # cursor.execute(sql)\n",
    "    # db.commit()\n",
    "    sys.exit()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Exception at {file} : {FILE_NAME}\")\n",
    "    print(f\"Exception: {e}\")\n",
    "    sys.exit()\n",
    "    \n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "            \n",
    "    if db:\n",
    "        db.close()\n",
    "        print(\"Disconnected from MySQL database\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
